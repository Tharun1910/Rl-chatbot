# ğŸ¤– Personalized Chatbot Using Reinforcement Learning

A conversational AI system built using Reinforcement Learning (RL) techniques to generate personalized, dynamic, and context-aware responses. Unlike traditional rule-based or supervised learning chatbots, this chatbot continuously refines its responses based on user interactions and sentiment-based rewards.

---

## ğŸ“‘ Project Overview

This project was developed as a final project for the **Applied Reinforcement Learning (CSC-724-U20)** course at the **University of South Dakota** under the guidance of **Dr. Rodrigue Rizk**.

The chatbot leverages:
- A pre-trained **DistilGPT-2** model for response generation.
- **Sentence-BERT** for query embeddings.
- **Stable-Baselines3 PPO (Proximal Policy Optimization)** for reinforcement learning.
- **Streamlit** for deploying a clean, interactive user interface.

---

## ğŸ“Š Features

- RL-driven personalized response selection.
- Sentiment-based reward mechanism to optimize conversations.
- Fine-tuned GPT-2 responses with diverse and coherent outputs.
- User-friendly, real-time web interface via Streamlit.
- Support for continuous model updates based on user feedback.

---

## ğŸ› ï¸ Tech Stack

- ğŸ Python 3.10+
- ğŸ¤– [Hugging Face Transformers]
- ğŸ’ª [Stable-Baselines3]
- ğŸ”¤ [Sentence-Transformers]
- ğŸŒ [Streamlit]
- ğŸ“Š [NLTK] for sentiment analysis

---

